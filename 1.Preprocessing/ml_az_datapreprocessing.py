# -*- coding: utf-8 -*-
"""ML-AZ_DataPreprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_MhiWvirP7IJcOR1W3FKmsai22pQSMmi

<h2> Importing the librairires</h2>
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""<h2>Importing the dataset</h2>
<ul>
  <li>X: features - independant variables</li>
  <li>y: dependant variable - what we want to predict</li>
</ul>
"""

dataset = pd.read_csv('Data.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

print(X)

print(y)

"""<h2>Taking care of missing data</h2>

<ul>
  <li>Delete the line if the dataset is big enough (1% of missing data)</li>
  <li>
    Replace the missing value by:
    <ul>
      <li>The average of the column</li>
      <li>The most frequent data of the column</li>
      <li>etc</li>
    </ul>
  </li>
</ul>

<p>We must change only numerical data, that's why we write X[:, 1:3], 3 is excluded.</p>
"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(X[:, 1:3])
X[:, 1:3] = imputer.transform(X[:, 1:3]) # do the replacement
print(X)

"""<h2>Enconding categorical data</h2>

<p>Encode non numerical data.<br>We can't assign 0 to France, 1 to Germany and 2 to Spain because the algorithm will understand that Spain>Germany>France, whereas not => binary vectors [1,0,0], [0,1,0], [0,0,1]</p>

ColumnTransformer instance parameters:
<ul>
  <p>Transformers:
  <ul>
    <li>Kind of transformation: encoding</li>
    <li>Kind of encodong: OneHotEncoding</li>
    <li>Index of column we want to encode</li>
  </ul>
  <p>Remainder:</p>
  <ul>
    <li>Keep other columns without change anything</li>
  </ul>
</ul>

"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
X = np.array(ct.fit_transform(X))
print(X)

"""<p>LabelEncoder encodes categorical binary data like yes/no</p>
<b>The matrix y doesn't need to be a numpy array !</b>
"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
print(y)

"""<h2>Splitting the dataset into the Training set and Test set</h2>

<p>random_state=1 to fix the seed (get the same split</p>
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
print("X_train: \n", X_train, "\n\ny_train: \n", y_train, "\n\nX_test: \n", X_test, "\n\ny_test: \n", y_test)

"""<h2>Feature Scaling</h2>

<p>To avoid some features to be dominated by other features.</p>
<p>We won't use the feature scaling of all our machine learning projects.</p>
<ul>
  <li>Standardisation: (x-mean(x))/(standard deviation(x))</li>
  <li>Normalisation: (x-min(x))/(max(x)-min(x))</li>
</ul>
"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])
X_test[:, 3:] = sc.transform(X_test[:, 3:])
print("X_train: \n",X_train, "\n\nX_test: ",X_test)